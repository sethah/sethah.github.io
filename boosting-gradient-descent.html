
<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="https://sethah.github.io/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="https://sethah.github.io/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="https://sethah.github.io/theme/font-awesome/css/font-awesome.min.css">


    <link href="https://sethah.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Seth's Blog Atom">



  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />


<meta name="author" content="Seth" />
<meta name="description" content="There are so many different ways to look at a machine learning algorithm and understand what it does, how it does it, and why it works. Linear regression can be thought of as minimizing a particular loss function or equivalently projecting a vector onto a subspace; SVMs can be thought of finding a hyperplane which maximizes the margin or equivalently finding basis coefficients of kernel functions which are members of a reproducing kernel Hilbert space!" />
<meta name="keywords" content="ml, boosting">
<meta property="og:site_name" content="Seth's Blog"/>
<meta property="og:title" content="Gradient boosting is gradient descent in function space"/>
<meta property="og:description" content="There are so many different ways to look at a machine learning algorithm and understand what it does, how it does it, and why it works. Linear regression can be thought of as minimizing a particular loss function or equivalently projecting a vector onto a subspace; SVMs can be thought of finding a hyperplane which maximizes the margin or equivalently finding basis coefficients of kernel functions which are members of a reproducing kernel Hilbert space!"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://sethah.github.io/boosting-gradient-descent.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2017-07-13 00:00:00-07:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://sethah.github.io/author/seth.html">
<meta property="article:section" content="posts"/>
<meta property="article:tag" content="ml"/>
<meta property="article:tag" content="boosting"/>
<meta property="og:image" content="/images/profile.jpg">

  <title>Seth's Blog &ndash; Gradient boosting is gradient descent in function space</title>

</head>
<body>
  <aside>
    <div>
      <a href="https://sethah.github.io">
        <img src="/images/profile.jpg" alt="" title="">
      </a>
      <h1><a href="https://sethah.github.io"></a></h1>


      <nav>
        <ul class="list">
          <li><a href="https://sethah.github.io/pages/about.html#about">About</a></li>

        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-linkedin" href="https://linkedin.com/in/sethah" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        <li><a class="sc-github" href="https://github.com/sethah" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-twitter" href="https://twitter.com/shendrickson16" target="_blank"><i class="fa fa-twitter"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href="https://sethah.github.io">    Home
</a>

      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>

      <a href="https://sethah.github.io/feeds/all.atom.xml">    Atom
</a>

    </nav>

<article class="single">
  <header>
    <h1 id="boosting-gradient-descent">Gradient boosting is gradient descent in function space</h1>
    <p>
          Posted on Thu 13 July 2017 in <a href="https://sethah.github.io/category/posts.html">posts</a>


    </p>
  </header>


  <div>
    <style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style>
<style type="text/css">
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are so many different ways to look at a machine learning algorithm and understand what it does, how it does it, and why it works. Linear regression can be thought of as minimizing a particular loss function or equivalently projecting a vector onto a subspace; SVMs can be thought of finding a hyperplane which maximizes the margin or equivalently finding basis coefficients of kernel functions which are members of a reproducing kernel Hilbert space!</p>
<p>I've read a great deal about gradient boosting and each explanation varies in its granularity and its perspective. Here, I'd like to start from the most generic perspective on gradient boosting and walk through the motivation and mechanics of the algorithm. Mainly, I'll be "explaining to myself" the classic paper by Friedman, <a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf">Greedy Function Approximation: A Gradient Boosting Machine</a>.</p>
<h2 id="Gradient-boosting-!=-gradient-boosted-decision-trees">Gradient boosting != gradient boosted decision trees<a class="anchor-link" href="#Gradient-boosting-!=-gradient-boosted-decision-trees">&#182;</a></h2><p>This might be more appropriate to mention after I've introduced the problem, but I think this is an important point. Gradient boosting is a method to build up a function as the sum of other functions. These individual functions <em>could be anything</em>, but in practice are usually made to be decision trees. In that case, we call it "gradient boosted decision trees" or "gradient boosted trees" or ... something similar. So, gradient boosting with decision trees is particular subset of the overall gradient boosting paradigm. To understand gradient boosting in the broader sense, I'll keep references to trees out of this post.</p>
<h2 id="The-machine-learning-problem">The machine learning problem<a class="anchor-link" href="#The-machine-learning-problem">&#182;</a></h2><p>First, separate yourself from the idea that machine learning is "minimizing a loss function over a training set." It is actually the idea that we have a system that produces a random outcome variable $y$ from a vector of explanatory variables $\mathbf{x}$. In this case we want to find a function that minimizes the expected value of the loss function over the distribution of all possible inputs and outputs.</p>
<p>$$
F^* = \arg \min_F E_{y, \mathbf{x}} L(y, F(\mathbf{x})) = \arg \min_F E_{\mathbf{x}} \left[E_y (L(y, F(\mathbf{x}))) | \mathbf{x} \right]
$$</p>
<p>For any given feature vector $\mathbf{x}$, the system can produce many different values of $y$. In fact, there's a distribution over $y$, and for any given $\mathbf{x}$, we want to find a function which minimizes the expected value of the loss function over all possible values of $y$. And since the explanatory variables take on values over a distribution, we want to further minimize the expectation over all possible values of $\mathbf{x}$.</p>
<p>In practice we don't know the true joint distributions of the inputs and outputs, so we seek to minimize the loss over a set of training samples $\{y_i, \mathbf{x}_i\}$ in hopes that it will provide a good approximation to the true minimizer.</p>
<h2 id="Optimization-with-parameters">Optimization with parameters<a class="anchor-link" href="#Optimization-with-parameters">&#182;</a></h2><p>We'll get more into what $F$ is momentarily, but consider how we approach many other machine learning problems. We would typically represent $F$ in terms of some finite number of "parameters" (think of parameters as being real numbers), and we'd then find the parameters that minimize the loss over the training set. In a linear regression, for example, the $F$ would be $F(\mathbf{x}) = \mathbf{\beta}^T\mathbf{x}$ where $\beta$ are the parameters that we use to represent $F$. Finding the $\beta_j$ that minimize the loss is the same as finding the linear function $F$ that minimizes the loss.</p>
<p>A common way find those parameters would be to start with some initial guess at the parameters, and then keep incrementing the parameters (or taking "steps") until we arrive at the optimum. In this way, we can think of the best parameters as an additive expansion of the form:</p>
<p>$$
\mathbf{P}^* = \sum_{m=0}^M \mathbf{p}_m
$$</p>
<p>In other words, we build up the best parameter vector as the sum of other parameter vectors. This is what optimization methods like gradient descent do.</p>
<h2 id="Optimization-with-functions">Optimization with functions<a class="anchor-link" href="#Optimization-with-functions">&#182;</a></h2><p>We're used to differentiating the loss with respect to parameters to get gradients for those parameters, but something more foreign is to differentiate the loss with respect to functions. Here, we wish to take a nonparametric approach, i.e. instead of representing the prediction function in terms of some parameters, we want to find an arbitrary prediction function which minimizes the loss.</p>
<p>It will be helpful to be able to think of a function as a vector whose entries are simply the values of the function $F(\mathbf{x})$ for every possible inpute $\mathbf{x}$ in the function's domain. In function space, the domain is infinite, so this would be an infinite length vector, but later we'll see cases where this will simplify to something finite.</p>
<p>As an example, consider the function $f(x) = \sin(x)$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[9]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.collections.PathCollection at 0x1102eada0&gt;</pre>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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">
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can think of the function $sin(x)$ as the vector $y$ in the code above.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[ -1.22464680e-16]
 [ -6.42787610e-01]
 [ -9.84807753e-01]
 [ -8.66025404e-01]
 [ -3.42020143e-01]
 [  3.42020143e-01]
 [  8.66025404e-01]
 [  9.84807753e-01]
 [  6.42787610e-01]
 [  1.22464680e-16]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the case of a true function defined for all x, imagine that vector growing ever longer as points on the graph are filled in at infinitely small intervals.</p>
<p>In the problem at hand, we can think of the loss function as a vector with infinite entries, one for each $\mathbf{x}$, where each entry is:</p>
<p>$$
\phi(F(\mathbf{x})) = E_y \left[ (L(y, F(\mathbf{x}))) | \mathbf{x} \right]
$$</p>
<p>The arbitrary function which best minimizes the loss is the sum of individual functions:</p>
<p>$$
F^*(\mathbf{x}) = \sum_{m=0}^M f_m(\mathbf{x})
$$</p>
<p>where the first function $f_0(\mathbf{x})$ is an initial guess and the subsequent $f_m(\mathbf{x})$ are function steps, usually in the direction of the gradient. To perform steepest descent using functions, we need to find the gradient, which is also a function. The gradient function is just:</p>
<p>$$
g_m(\mathbf{x}) = \left[\frac{\partial \phi(F(\mathbf{x}))}{\partial F(\mathbf{x})}\right]_{F(\mathbf{x}) = F_{m-1}(\mathbf{x})}
$$</p>
<p>You can show that this reduces to:</p>
<p>$$
g_m(\mathbf{x}) = E_y \left[\frac{\partial L(y, F(\mathbf{x}))}{\partial F(\mathbf{x})}|\mathbf{x}\right]_{F(\mathbf{x}) = F_{m-1}(\mathbf{x})}
$$</p>
<p>So, the gradient is a function, or infinite dimensional vector, with each entry being the derivative of the loss function with respect to $F(\mathbf{x})$ at a particular value for $\mathbf{x}$.</p>
<p>To make it slightly more concrete, consider the squared-error loss:</p>
<p>$$
L(y, F(\mathbf{x})) = \frac{1}{2}(y -  F(\mathbf{x}))^2 \\
g_m(\mathbf{x}) = E_y \left[(y -  F(\mathbf{x}))|\mathbf{x}\right]_{F(\mathbf{x}) = F_{m-1}(\mathbf{x})}
$$</p>
<p>So the gradient function in this case is the expected value of $y -  F(\mathbf{x})$ for each value of $\mathbf{x}$. Neat!</p>
<h2 id="Finite-data">Finite data<a class="anchor-link" href="#Finite-data">&#182;</a></h2><p>In practice, the gradient function is only defined at N data points since the function F only affects the loss when evaluated at the individual $\mathbf{x}_i$. Because of this, we can think of the functions as <em>N-dimensional</em> vectors, and the gradient function also as an N-dimensional vector.</p>
<p>$$
\mathbf{g}_m = \{-g_m(\mathbf{x}_i)\}_1^N \\
g_m(\mathbf{x}_i) = \left[\frac{\partial L(y, F(\mathbf{x}_i))}{\partial F(\mathbf{x}_i)}|\mathbf{x}_i\right]_{F(\mathbf{x}) = F_{m-1}(\mathbf{x})}
$$</p>
<p>If we want to iteratively add up arbitrary N-dimensional vectors without any constraints to get to one that minimizes the training loss, we'll end up with the vector $\mathbf{y}$. But this is a useless model! Think of it as a <em>partial</em> function that is only defined for values of $\mathbf{x}$ that appear in the training set. It's just the vector of training labels!</p>
<p>It doesn't predict any other values than what's in the training set. Instead, we can choose to add functions that are members of a parameterized class of functions $h(\mathbf{x}; \mathbf{a})$ which produces functions $\mathbf{h}_m = \{h(\mathbf{x}_i; \mathbf{a}_m)\}_1^N$ that are most parallel to $-\mathbf{g}_m \in \mathbb{R}^N$.</p>
<p>That way, we are still stepping approximately in the direction of the gradient function in the N-dimensional data space, but using functions which are defined for all possible inputs such that they generalize beyond the training set. This is like constrained gradient descent in function space.</p>
<p>More specifically, at each step we will add a function $h(\mathbf{x}; \mathbf{a})$ that is "closest" to the gradient vector by finding the parameters of h that minimize the following:</p>
<p>$$
\mathbf{a}_m = \arg \min_{\mathbf{a}, \beta} \sum_{i=1}^N\left[-g_m(\mathbf{x}_i) - \beta h(\mathbf{x}_i;\mathbf{a})\right]^2
$$</p>
<p>This produces a "constrained" negative gradient $h(\mathbf{x}; \mathbf{a}_m)$ that is used in place of the unconstrained gradient $\mathbf{g}_m$. At each boosting step, the function $F$ is updated as:</p>
<p>$$
F_m(\mathbf{x}) = F_{m-1}(\mathbf{x}) + \rho_m h(\mathbf{x}; \mathbf{a}_m)
$$</p>
<p>where the step size $\rho_m$ is determined via the line search:</p>
<p>$$
\rho_m = \arg \min_{\rho} \sum_{i=1}^N L\left(y_i, F_{m-1}(\mathbf{x}_i) + \rho h(\mathbf{x}_i; \mathbf{a}_m)\right)
$$</p>
<h2 id="Algorithm:-Gradient-Boost">Algorithm: Gradient Boost<a class="anchor-link" href="#Algorithm:-Gradient-Boost">&#182;</a></h2><ol>
<li>$F_0(\mathbf{x}) = \arg \min_\rho \sum_{i=1}^N L(y_i, \rho)$</li>
<li>$\text{For } m = 1 \text{ to } M \text{ do:}$</li>
<li>$\tilde{y} = -\left[\frac{\partial L(y_i, F(\mathbf{x}_i))}{\partial F(\mathbf{x}_i)}\right]$</li>
<li>$\mathbf{a}_m = \arg \min_{\mathbf{a}, \beta} \sum_{i=1}^N\left[-g_m(\mathbf{x}_i) - \beta h(\mathbf{x}_i;\mathbf{a})\right]^2$</li>
<li>$\rho_m = \arg \min_{\rho} \sum_{i=1}^N L\left(y_i, F_{m-1}(\mathbf{x}_i) + \rho h(\mathbf{x}_i; \mathbf{a}_m)\right)$</li>
<li>$F_m(\mathbf{x}) = F_{m-1}(\mathbf{x}) + \rho_m h(\mathbf{x}; \mathbf{a}_m)$</li>
<li>$\text{end For}$</li>
<li>$\text{end Algorithm}$</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="#References">&#182;</a></h2><p>This post was an attempt at explaining sections 1, 2, and 3 of the paper by Jerome Friedman.</p>
<ul>
<li>Friedman. "Greedy Function Approximation: A Gradient Boosting Machine." <a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf">https://statweb.stanford.edu/~jhf/ftp/trebst.pdf</a></li>
</ul>

</div>
</div>
</div>
 


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://sethah.github.io/tag/ml.html">ml</a>
      <a href="https://sethah.github.io/tag/boosting.html">boosting</a>
    </p>
  </div>




</article>

    <footer>
<p>&copy; Seth Hendrickson </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>





<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Seth's Blog ",
  "url" : "https://sethah.github.io",
  "image": "/images/profile.jpg",
  "description": ""
}
</script>
</body>
</html>